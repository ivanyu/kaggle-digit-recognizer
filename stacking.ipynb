{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "from os import path\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from classify_base import load_data, enumerate_and_write_predictions\n",
    "import meta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level_0_clfs = [\n",
    "#     {\n",
    "#         'name': 'random_forest_1',\n",
    "#         'classifier_creator': lambda: RandomForestClassifier(\n",
    "#             n_estimators=200,\n",
    "#             criterion='gini',\n",
    "#             max_features='sqrt',\n",
    "#             max_depth=None,\n",
    "#             n_jobs=3),\n",
    "#         'preprocessing': [\n",
    "#             MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "#         ],\n",
    "#         'persistence': True\n",
    "#         # [ 0.96573468  0.96679757  0.96332897  0.96594022  0.96665079]\n",
    "#     },\n",
    "#     {\n",
    "#         'name': 'ada_boost_1',\n",
    "#         'classifier_creator': lambda: AdaBoostClassifier(\n",
    "#             n_estimators=1000, learning_rate=1.0),\n",
    "#         'preprocessing': [\n",
    "#             MinMaxScaler(feature_range=(0, 1), copy=True),\n",
    "#             PCA(n_components=35, whiten=True)\n",
    "#         ],\n",
    "#         'persistence': True\n",
    "#         # [0.64259369  0.70272522  0.70436957  0.72656901  0.71069557]\n",
    "#     },\n",
    "#     {\n",
    "#         'name': 'svm_1',\n",
    "#         'classifier_creator': lambda: SVC(\n",
    "#             C=2.8, kernel='rbf', gamma=0.0073, cache_size=2000, probability=True),\n",
    "#         'preprocessing': [\n",
    "#             MinMaxScaler(feature_range=(0, 1), copy=True),\n",
    "#             PCA(n_components=35, whiten=True)\n",
    "#         ],\n",
    "#         'persistence': True\n",
    "#     },\n",
    "#     {\n",
    "#         'name': 'svm_2',\n",
    "#         'classifier_creator': lambda: SVC(\n",
    "#             C=1000, kernel='rbf', gamma=0.049, cache_size=2000, probability=True),\n",
    "#         'preprocessing': [\n",
    "#             MinMaxScaler(feature_range=(0, 1), copy=True),\n",
    "#             PCA(n_components=35, whiten=True)\n",
    "#         ],\n",
    "#         'persistence': True\n",
    "#     },\n",
    "#     {\n",
    "#         'name': 'knn3',\n",
    "#         'classifier_creator': lambda: KNeighborsClassifier(\n",
    "#             n_neighbors=3, n_jobs=-1),\n",
    "#         'preprocessing': [\n",
    "#             MinMaxScaler(feature_range=(0, 1), copy=True),\n",
    "#             PCA(n_components=35, whiten=True)\n",
    "#         ],\n",
    "#         'persistence': True\n",
    "#     },\n",
    "#     {\n",
    "#         'name': 'knn7',\n",
    "#         'classifier_creator': lambda: KNeighborsClassifier(\n",
    "#             n_neighbors=7, n_jobs=-1),\n",
    "#         'preprocessing': [\n",
    "#             MinMaxScaler(feature_range=(0, 1), copy=True),\n",
    "#             PCA(n_components=35, whiten=True)\n",
    "#         ],\n",
    "#         'persistence': True\n",
    "#     },\n",
    "    {\n",
    "        'name': 'mlp1',\n",
    "        'classifier_creator': None,\n",
    "        'preprocessing': None,\n",
    "        'persistence': True\n",
    "    },\n",
    "    {\n",
    "        'name': 'mlp2',\n",
    "        'classifier_creator': None,\n",
    "        'preprocessing': None,\n",
    "        'persistence': True\n",
    "    },\n",
    "    {\n",
    "        'name': 'mlp2aug',\n",
    "        'classifier_creator': None,\n",
    "        'preprocessing': None,\n",
    "        'persistence': True\n",
    "    },\n",
    "    {\n",
    "        'name': 'cnn1',\n",
    "        'classifier_creator': None,\n",
    "        'preprocessing': None,\n",
    "        'persistence': True\n",
    "    },\n",
    "    {\n",
    "        'name': 'cnn2',\n",
    "        'classifier_creator': None,\n",
    "        'preprocessing': None,\n",
    "        'persistence': True\n",
    "    },\n",
    "    {\n",
    "        'name': 'cnn2_psblb',\n",
    "        'classifier_creator': None,\n",
    "        'preprocessing': None,\n",
    "        'persistence': True\n",
    "    },\n",
    "#     {\n",
    "#         'name': 'xgb1',\n",
    "#         'classifier_creator': None,\n",
    "#         'preprocessing': None,\n",
    "#         'persistence': True\n",
    "#     },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = 'stacking_models'\n",
    "if not path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "(X_train_original, y_train_original, X_test_original) = load_data(None)\n",
    "\n",
    "n_classes = meta.N_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "folds = list(kfold.split(np.arange(0, X_train_original.shape[0])))\n",
    "\n",
    "for (a, b) in folds:\n",
    "    assert np.all(np.sort(np.concatenate((a, b))) == np.arange(0, X_train_original.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacking_train = np.zeros((X_train_original.shape[0], n_classes * len(level_0_clfs)))\n",
    "stacking_test = np.zeros((X_test_original.shape[0], n_classes * len(level_0_clfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing mlp1\n",
      "\n",
      "Doing mlp2\n",
      "\n",
      "Doing mlp2aug\n",
      "\n",
      "Doing cnn1\n",
      "\n",
      "Doing cnn2\n",
      "\n",
      "Doing cnn2_psblb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf_n, clf_item in enumerate(level_0_clfs):\n",
    "    clf_name = clf_item['name']\n",
    "    clf_creator = clf_item['classifier_creator']\n",
    "    preprocessing = clf_item['preprocessing']\n",
    "    if preprocessing is None:\n",
    "        preprocessing = []\n",
    "    persistence = clf_item['persistence']\n",
    "    \n",
    "    print('Doing', clf_name)\n",
    "\n",
    "    X_train_all = X_train_original.copy()\n",
    "    X_test = X_test_original.copy()\n",
    "\n",
    "    for prep in preprocessing:\n",
    "        X_train_all = prep.fit_transform(X_train_all)\n",
    "        X_test = prep.transform(X_test)\n",
    "\n",
    "    fold_pred_file_name = path.join(MODEL_DIR, '{}_folds.npy'.format(clf_name))\n",
    "    if persistence and path.exists(fold_pred_file_name):\n",
    "        stacking_train[:, clf_n * n_classes : (clf_n + 1) * n_classes] = np.load(fold_pred_file_name)\n",
    "    else:\n",
    "        for fold_n, (train_idxs, val_idxs) in enumerate(folds):\n",
    "            print(\"Fold\", fold_n)\n",
    "            X_train = X_train_all[train_idxs]\n",
    "            y_train = y_train_original[train_idxs]\n",
    "            X_val = X_train_all[val_idxs]\n",
    "            y_val = y_train_original[val_idxs]\n",
    "\n",
    "            clf = clf_creator()\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            predictions = clf.predict(X_val)\n",
    "            accuracy = accuracy_score(y_val, predictions)\n",
    "            print(accuracy)\n",
    "\n",
    "            stacking_train[val_idxs, clf_n * n_classes : (clf_n + 1) * n_classes] = clf.predict_proba(X_val)\n",
    "\n",
    "        np.save(fold_pred_file_name, stacking_train[:, clf_n * n_classes : (clf_n + 1) * n_classes])\n",
    "\n",
    "    full_pred_file_name = path.join(MODEL_DIR, '{}_full.npy'.format(clf_name))\n",
    "    if persistence and path.exists(full_pred_file_name):\n",
    "        stacking_test[:, clf_n * n_classes : (clf_n + 1) * n_classes] = np.load(full_pred_file_name)\n",
    "    else:\n",
    "        print(\"Full\")\n",
    "        clf = clf_creator()\n",
    "        clf.fit(X_train_all, y_train_original)\n",
    "        stacking_test[:, clf_n * n_classes : (clf_n + 1) * n_classes] = clf.predict_proba(X_test)\n",
    "        \n",
    "        np.save(full_pred_file_name, stacking_test[:, clf_n * n_classes : (clf_n + 1) * n_classes])\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0000000318801421"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(stacking_train[0:1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#level_1_clf = SVC(C=0.1, kernel='rbf')\n",
    "level_1_clf = LogisticRegression()\n",
    "level_1_clf.fit(stacking_train, y_train_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 9 ..., 3 9 2]\n"
     ]
    }
   ],
   "source": [
    "predictions = level_1_clf.predict(stacking_test)\n",
    "print(predictions)\n",
    "enumerate_and_write_predictions(predictions.reshape((stacking_test.shape[0], 1)), 'stacking.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
